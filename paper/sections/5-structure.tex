\section{Structuring and sequencing arithmetic} \label{sec:structure}
Floating-point operations are not associative. It is well-known that the
round-off error of a sequence of additions is linear in the height of the
computation tree. Recalling our running example from Section~\ref{sec:overview},
consider the expression 
$w \tilde{+} x \tilde{+} y \tilde{+} z$.
Consider the following two ways to associate this expression:
\begin{description}
  \item[The degenerate way.] The abstract syntax tree here resembles the
    structure of a linked-list. Error terms grow in $O(n)$, where $n$ is the
    number of subterms: $$((w \tilde{+} x) \tilde{+} y) \tilde{+} z$$
  \item[The balanced tree way.] The abstract syntax tree represents a balanced
    binary tree. Error terms grow in $O(ln(n))$. $$(w \tilde{+} x) \tilde{+} (y
    \tilde{+} z)$$
\end{description}
It is clear from this example that the clever user may wish to structure and
sequence computation in a manner that minimizes the height of their computation
tree.

Unfortunately, for a given sequence of additions, the characteristic monadic
bind rule in Negative Fuzz (without factor) forces the error to grow in $O(n)$
of the number of added subterms.
To understand why, we look to the type of the floating point addition
function:
\footnote{For the remainder of this section, we omit the interval bound
subscripts.}
$\textbf{addfp} : (\textbf{num} \times \textbf{num}) \multimap M_u \textbf{num}$.
The issue occurs when we try to pass two computations of type $M_q \textbf{num}$
to $\textbf{addfp}$. 
Recall from Figure~\ref{fig:monadic-bind-again} that the monadic bind rule 
\begin{figure}[ht] \label{fig:monadic-bind-again}
\AXC{$\Gamma \vdash e : M_r \tau_0$}
\AXC{$\Theta, x:_{s} \tau_0 \vdash f : M_{q} \tau$}
\RightLabel{($M_u$ E)}
\BIC{$s * \Gamma + \Theta \vdash \letbind x = e \ \tin \ f : M_{s*r+q} \tau$}
\bottomAlignProof
\DisplayProof
\end{figure}
is the only way to eliminate the monadic $M_q \tau$ type. Consider the the
following program sketch shown in Figure~\ref{fig:sketch} where we try to
compute $(w \tilde{+} x) \tilde{+} (y \tilde{+} z)$ and $((w \tilde{+} x)
\tilde{+} y) \tilde{+} z$. Due to the grades on our monadic bind rule, for both
programs the same expression in \lstinline{HOLE?} will yield the same type and
error grade. Although the height of the corresponding \textit{computation tree}
differs in Figure~\ref{fig:sketch}, the height of the number of applications of
the monadic bind rule in the \textit{typing tree} does not differ. The Numerical
Fuzz type system is incapable of distinguishing between the two different
program sketches. 
\begin{figure}[ht]
\centering

\begin{subfigure}[t]{0.48\textwidth}
\begin{lstlisting}
// Assuming HOLE? has type:
  a :_s0 num b :_s1 num |- HOLE? : M_q num
// Our program will have type:
  M[s1 * (s0 * u + u) + q] num 
let-bind a = addfp <w, x> in
let-bind b = addfp <y, z> in
HOLE?
\end{lstlisting}
\caption{Partial program sketch of $(w \tilde{+} x) \tilde{+} (y \tilde{+} z)$ corresponding the perfect binary computation tree}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.48\textwidth}
\begin{lstlisting}
// Assuming HOLE? has type:
  a :_s0 num b :_s1 num |- HOLE? : M_q num
// Our program will have type: 
  M[s1 * (s0 * u + u) + q] num 
let-bind a = addfp <w, x> in
let-bind b = addfp <a, y> in
HOLE?
\end{lstlisting}
\caption{Partial program sketch of $((w \tilde{+} x) \tilde{+} y) \tilde{+} z$ corresponding to the degenerate computation tree}
\end{subfigure}

\caption{Partial programs after eliminating the two monadic types obtained by
floating-point additions. Observe that given the same \lstinline{HOLE?}, both
programs will have the same type.}
\end{figure}

% % We are able to construct $M_q \textbf{num} \times M_q
% % \textbf{num}$
% To explore how we might avoid this problem, we can look to the role of $\times$
% in linear logic.
% % In this section, we omit our interval annotations for presentational purposes.
% % Further, recall that $\textbf{addfp}$ and $\textbf{subfp}$ have type $(\textbf{num}
% % \times \textbf{num}) \multimap M_q ~ \textbf{num}$.
% In linear logic, $\tau_0 \times \tau_1$ (written as $\&$ in linear logic and
% pronounced \textit{with}) is also known as internal choice: for a given typing
% context, the consumer gets to decide whether to allocate the context towards
% constructing $\tau_0$ or $\tau_1$. From the producer's perspective, a type
% $\tau_0 \times \tau_1$ in a context $\Gamma$ indicates that we can share the
% context in $\Gamma$ towards the construction of $\tau_0$ and $\tau_1$ as only
% one will eventually be consumed (consumer's choice). We can view the
% introduction rule as allowing $\tau_0$ and $\tau_1$ to share contexts $\Gamma$,
% their construction. Correspondingly, the elimination rules can be viewed as
% forcing consumers to internally choose between consuming $\Gamma$ towards either
% constructing $\tau_1$ or $\tau_2$.
% Unfortunately, for types that need to be sequenced, such as our monadic and
% comonadic types, our sequencing rules require the typing contexts to be split
% up, thereby prohibiting sharing.
We now look for ways to avoid unnecessarily sequencing our computation so that
the numerical analysis performed in the type system aligns better with the
corresponding computation tree.
We observe that the primitive $\textbf{factor}: (M_q \tau_0) \times (M_q \tau_1)
\multimap M_q (\tau_0 \times \tau_1)$ is sound 
(proved in Theorem~\ref{thm:metric-preservation}) and also allows for balanced
computation trees. 
% todo: is it admissible or derivable?
% It would also allow monadic types $M_q ~ \tau_0$ and $M_q \tau_1$ that
% would ordinarily need to be sequenced in a manner that would prohibit the
% sharing of contexts to be constructed with a shared $\Gamma$ and combined to
% form a $M_q (\tau_0 \times \tau_1)$.
% As we show below,
% $\textbf{factor}$ is a particularly useful primitive to have for sequencing
% computations. 
% To enabling the sharing of round-off and sensitivity information, we simply add
% the new primitive $\textbf{factor} : (M_q \tau_0 \times M_r \tau_1) \multimap
% M_{max(q, r)} (\tau_0 \times \tau_1)$ witnessing the resource interpretation and
% allowing for error and sensitivity information to be shared between monadic
% terms.
Armed with a new primitive and more expressive language, we now return to our
running example. In Figure~\ref{fig:factor-side-by-side}, 
we demonstrate how the $\textbf{let-bind}$ rule interacts with our linear
$\times$ to enable more efficiently structured computation. 
\begin{figure}[ht]
\centering

\begin{subfigure}[t]{0.48\textwidth}
\begin{lstlisting}
// (w + x) + (y + z) : M[3*u] num 
let-bind a = addfp <w, x> in
let-bind b = addfp <y, z> in
let-bind c = addfp <a, b> in
addfp c 
\end{lstlisting}
\caption{Without \textbf{factor}.}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.48\textwidth}
\begin{lstlisting}
// (w + x) + (y + z) : M[2*u] num 
let-bind a = 
  factor <addfp <w, x>, addfp <y, z>> in
  addfp a
\end{lstlisting}
\caption{With \textbf{factor}.}
\end{subfigure}

\caption{Side-by-side comparison with and without the \textbf{factor} primitive
of $(w \tilde{+} x) \tilde{+} (y \tilde{+} z)$ corresponding to the prefect
binary tree .}
\label{fig:factor-side-by-side}
\end{figure}
Note that $u$ represents the unit round-off associated with $\textbf{addfp}$. In
the summation example, the program with \textbf{factor} has an error bound of
two ULPs whereas the program without \textbf{factor} has an error bound of three
ULPs. Clearly, $\textbf{factor}$ helps users design programs that achieve
tighter error bounds.

% We now explore whether our typing rules can derive the equivalence between $M_q
% (\tau_0 \times \tau_1)$ and $M_q \tau_0 \times M_q \tau_1$.
Interestingly, the inverse type 
$\textbf{distribute} : M_q (\tau_0 \times \tau_1) \multimap (M_q \tau_0) \times (M_q \tau_1)$
is derivable, so no special primitive is needed to structure arithmetic in the
reverse direction:
\begin{equation*} \label{eq:distribute}
\begin{aligned}[c]
\textbf{distribute} &: M_q (\tau_1 \times \tau_2) \multimap (M_q \tau_1 \times M_q \tau_2) \\
 & \triangleq \lambda ~ y. ~ 
   \langle
     \textbf{let-bind} \ x ~ = ~ y \ \textbf{in} \ \textbf{ret}(\pi_1 ~ x),
     \textbf{let-bind} \ x ~ = ~ y \ \textbf{in} \ \textbf{ret}(\pi_2 ~ x),
   \rangle
\end{aligned}
\end{equation*}
Further, the comonadic sequencing rule does not have such a corresponding
restriction as both
\begin{equation}
  \begin{aligned}[c]
  \textbf{cofactor} &: (!_s \tau_0) \times (!_s \tau_1) \multimap !_s (\tau_0 \times \tau_1) \\
  \textbf{cofactor} &\triangleq \lambda e. [\langle \textbf{let-cobind} \ x \ = \ \pi_0 \ e \ \textbf{in} \ x , \textbf{let-cobind} \ y \ = \ \pi_1 \ e \ \textbf{in} \ y \rangle]\\
  \end{aligned}
\end{equation}
and
\begin{equation}
  \begin{aligned}[c]
    \textbf{codistribute} &: !_s (\tau_0 \times \tau_1) \multimap (!_s \tau_0) \times (!_s \tau_1) \\
    \textbf{codistribute} &\triangleq \lambda e. \textbf{let-cobind} \ x \ = \ e \ \textbf{in} \ \langle [\pi_0 ~ x], [\pi_1 ~ x] \rangle \\
  \end{aligned}
\end{equation}
are derivable.

% In particular, the ability for a producer to share resources interacts poorly with our
% sequenced $\textbf{let-bind}$ and call-by-value evaluation strategy, which
% pessimistically prohibits the sharing of resources between the bound argument
% and the body. If we have two monadic types $M_q \tau_0 \times M_q \tau_1$ that
% shared resources in their construction, we have no way of constructing $M_q
% (\tau_0 \times \tau_1)$ with a shared error grade. A similar problem exists for
% sharing context sensitivities. 


We now explore the interaction between $\textbf{factor}$ and subtraction. TODO??

\subsection{Automatic inference of factor}
We now describe an automatic program transformation $\textsc{factorize}$ that
can insert $\textbf{factor}$ in a program that is strictly sequenced without
$\textbf{factor}$. We assume that each variable is unique (no shadowing).

We first recusively transform the program so that it is in administrative normal
form. In particular, we desire that every application is of an
expression to a variable (e.g. $e \ x$) or operation to a variable (e.g.
$\textbf{op} \ y$). 
% The non-structural cases of the transformation are provided below:
%
% \begin{equation}
%   \begin{aligned}[c]
%     \textsc{preprocess}(e \ f) &= \textbf{let} \ x \ = \ f \ \textbf{in} \ e \ x \quad \quad &\text{ (for $f$ not a variable)} \\
%     \textsc{preprocess}(\textbf{op} \ e) &= \textbf{let} \ x \ = \ e \ \textbf{in} \ \textbf{op} \ x \quad \quad &\text{ (for $e$ not a variable)} 
%   \end{aligned}
% \end{equation}

Now, we we can define $\textsc{factorize}$, which syntatically operates on pairs
of well-typed programs in adminstrative normal form and \textit{monadic maps}
$\sigma$, which maps variables to expressions of monadic type. These maps behave
similarly to substutiton maps. $\textsc{transform}$ returns the transformed
program fragment and sets of variables that have been used by factor. It has
type:
% max: hmm this last part doesn't quite make sense wrt sets of vars
$$
\textsc{factorize} : \text{program} \to (\text{var} \rightharpoonup \text{program}) \to
(\text{program} \times \text{sets of variables})
$$

% By default, for all variables $x$, $\sigma[x] = x$ if $x$ is not
% otherwise defined in $\sigma$.

% \begin{equation}
%   \textsc{factorize}(e) = \textsc{sequence}(\textsc{factorize-rec}(e, \emptyset))
% \end{equation}

We use $V$ as a metavariable to represent a set of variables. We first detail
the interesting cases for our program transformation:

\begin{equation}
\begin{aligned}[c]
  \textsc{factorize}(\textbf{let-bind} \ x \ = \ e \ \textbf{in} \ f, \sigma) &= 
  \begin{aligned}
    \text{let} \ (g, V) \ = (\textsc{factorize}(f, \sigma;[x \mapsto \text{fst} \ \textsc{factorize}(e, \sigma)])) \ \text{in} \\
    \text{if} \ x \in V \\
    \text{then} \ (g, V) \\
    \text{else} \ (\textbf{let-bind} \ x \ = \ e \ \textbf{in} \ g, V \cup \{x\})\\
  \text{(if x only occurs once in f)}
  \end{aligned}
  \\
  \\
  \textsc{factorize}(\textbf{let} \ z \ = \ \langle x, y \rangle \ \textbf{in} \ f, \sigma) &= 
  \begin{aligned}
    \text{let} \ (g, V) = \textsc{factorize}(f, \sigma) \ \text{in}\\
    \text{if} \ x, y \in DOM(\sigma) \\
    \text{then} \ (\textbf{let-bind} \ z = \ \textbf{factor} \ \langle \sigma[x], \sigma[y] \rangle \ \textbf{in} \ g, V \cup \{x, y\})\\
    \text{else} \ (\textbf{let} \ z \ = \ \langle x, y \rangle \ \textbf{in} \ g,
    V) \\
  \end{aligned} \\
  \\
  \textsc{factorize}(e \ f, \sigma) &= 
  \begin{aligned}
    \text{let} \ (g, V_0) = \textsc{factorize}(e, \sigma) \ \text{in}\\
    \text{let} \ (h, V_1) = \textsc{factorize}(f, \sigma) \ \text{in}\\
    (g \ h, V_0 \cup V_1)
  \end{aligned} \\
\end{aligned}
\end{equation}
Now, we detail our base case for variables:
\begin{equation}
  \begin{aligned}
    \textsc{factorize}(x, \sigma) &= (x, \{\})
  \end{aligned}
\end{equation}
and our base case for constants:
\begin{equation}
  \begin{aligned}
    \textsc{factorize}(k, \sigma) &= (k, \{\})
  \end{aligned}
\end{equation}
The remainder of the rules are recursive and structural. Invoking the program
transformation on a well-typed program transformation $. \vdash e : \tau$
can be done by calling: $\textsc{factorize} ~ e ~ \emptyset$.

\subsubsection{Program transformation properties}
We now wish to prove that our program transformation is sound and never results
in looser error bounds.
\begin{theorem}[Factorization soundness]
  For any program $. \vdash e : \tau$ and $(e', \sigma) = \textsc{factorize} \ e \
  \emptyset$, we have that $. \vdash e' : \tau'$ where $\tau' \subseteq \tau$.
\end{theorem}
\begin{proof}
  We first generalize the hypothesis to be over all typing contexts $\Gamma$.
  We induct over the typing derivation. 
  We strengthen the inductive hypothesis with the assumption that our map
  $\sigma: \text{var} \rightharpoonup \text{program}$ only maps variables $x_0,
  x_1, x_n$ defined in the typing context $\Gamma$ such that $\Gamma \vdash
  \sigma[x] : M_u \ \Gamma[x]$ is well-typed and a output guarantee that for all
  $x \in DOM(\sigma)$:
  \begin{enumerate}
    \item If $x \in \sigma$, $\Gamma \vdash e' : \tau'$ for $\tau' \subseteq
      \tau$ (substitution occured with \textbf{factor}).
    \item If $x \not\in \sigma$, $\Gamma, x : \tau \vdash e' : \tau'$ for $\tau' \subseteq
      \tau$ (substitution did not occur, revert).
  \end{enumerate}
  We proceed with our induction: 
  \begin{description}
    \item[Base cases (variables, constants, etc.).] Holds trivially as the
      transformation does nothing.
    \item[Let.] TODO.
    \item[Let-bind ($M_u E$).] TODO.
  \end{description}
\end{proof}
