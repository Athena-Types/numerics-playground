\section{Implementation and evaluation} \label{sec:eval}
We wish to have a practical technique for bounding floating-point round-off
error. To evaluate the practicality of our approach, we implement the type
inference algorithm detailed in this paper in Rust.
We evaluate our implementation on speed and precision of the analysis against
competiting tools on benchmarks in the FPBench benchmark suite \cite{fpbench}.
For our comparison, we use the precision specified in the corresponding FPBench
benchmark spec (e.g. \textsc{binary32}, \textsc{binary64}) and set the rounding
mode to round towards zero. \footnote{The add-assoc benchmark is not from
FPBench and is instead taken from our running example.}

\paragraph{Supported operations.}
Compared to Numerical Fuzz, our instantiation supports subtraction,
multiplication, and addition. We additionally support negative numbers. However,
we do not support division or taking square roots; we leave this as a potential
future direction in future work. 


\paragraph{Precision on relative error.}
We compare the precision of our absolute error bounds against two alternative
approaches: FPTaylor \cite{fptaylor} and Gappa \cite{gappa}. In all of the
examples in Table~\ref{tab:bounds-abs}, we can see that PairFuzz's bounds are
tighter when \textbf{factor} is used.
We also observe that PairFuzz (with factor) obtains competitive bounds within an
order of magnitude with Gappa and FPTaylor, and occasionally produces tighter
bounds than Gappa.

\begin{footnotesize}
  \begin{table}[htbp]
\centering
\begin{tabular}{lllllllll}
\toprule
Benchmark & PairFuzz (no factor) & PairFuzz (with factor) & Gappa & FPTaylor &  &  &  &  \\
\midrule
sum & 2.665E-14 & 1.332E-14 & 6.661E-15 & 4.441E-15 &  &  &  &  \\
kepler0 & 9.534E-13 & 6.81E-13 & 1.982E-13 & 1.171E-13 &  &  &  &  \\
% shoelace-formula & 3.997E-09 & \textbf{1.998E-09} &  &  &  &  &  &  \\
himmilbeau & 1.122E-11 & 5.986E-12 & 2E-12 & 1.18E-12 &  &  &  &  \\
sineOrder3 & 5.937E-15 & 4.241E-15 & 2.069E-15 & 9.206E-16 &  &  &  &  \\
matrixDeterminant2 & 2.265E-11 & 6.661E-12 & 7.006E-12 & 3.126E-12 &  &  &  &  \\
rigidBody1 & 9.792E-13 & 8.16E-13 & 5.898E-13 & 4.263E-13 &  &  &  &  \\
delta4 & 1.144E-12 & 5.004E-13 & 1.768E-13 & 1.154E-13 &  &  &  &  \\
sqroot & 4.857E-15 & 1.735E-15 & 1.041E-15 & 9.714E-16 &  &  &  &  \\
rigidBody2 & 2.035E-10 & 1.018E-10 & 7.213E-11 & 4.543E-11 &  &  &  &  \\
matrixDeterminant & 2.265E-11 & 6.661E-12 & 7.006E-12 & 3.126E-12 &  &  &  &  \\
test01\_sum3 & 1.431E-05 & 7.153E-06 & 3.576E-06 & 2.384E-06 &  &  &  &  \\
kepler1 & 5.944E-12 & 2.843E-12 & 7.456E-13 & 3.918E-13 &  &  &  &  \\
add-assoc* & 2.665E-12 & 1.776E-12 & 1.364E-12 & 9.095E-13 &  &  &  &  \\
\bottomrule
\end{tabular}
\caption{Comparison of the precision of PairFuzz (with and without
\textbf{factor}) against Gappa and FPTaylor. All bounds are absolute error
bounds.}
\label{tab:bounds-abs}
\end{table}
\end{footnotesize}

\paragraph{Precision on absolute error.}
We now compare the precision of our relative error bounds. Note that
many of our example benchmark programs from FPBench contain subtraction or
negative numbers. This is a challenge for static numerical analysis tools to
determine if a program can output zero, which would make relative error
undefined.
In Table~\ref{tab:bounds-rel}, we compare the precision of our relative error
bounds against two alternative approaches.
In the add-assoc and sqroot benchmark, all tools manage to bound away from zero.
PairFuzz (with factor) produces the tightest error bound in add-assoc and
produces competitive results in the sqroot benchmark. 

\begin{footnotesize}
\begin{table}[htbp]
\centering
\begin{tabular}{lllllllll}
\toprule
Benchmark & PairFuzz (no factor) & PairFuzz (with factor) & Gappa & FPTaylor &  &  &  &  \\
\midrule
sum &  &  &  & 1.011E-15 &  &  &  &  \\
kepler0 &  &  &  & 2.434E-15 &  &  &  &  \\
sqroot & 3.775E-15 & 1.332E-15 & 1.202E-15 & 8.883E-16 &  &  &  &  \\
test01\_sum3 &  &  &  & 5.427E-07 &  &  &  &  \\
kepler1 &  &  &  & 7.654E-15 &  &  &  &  \\
add-assoc & 6.661E-16 & 4.441E-16 & 6.661E-16 & 2.22E-15 &  &  &  &  \\
\bottomrule
\end{tabular}
\caption{Comparison of the precision of PairFuzz (with and without
  \textbf{factor}) against Gappa and FPTaylor. All bounds are relative error
  bounds. Blank entries indicate where the tools had trouble bounding the result
  away from zero due to the presence of subtraction or negative numbers. On 8 of
the 14 benchmarks, all tools failed to bound away from zero and have been
omitted from the table for brevity.}
\label{tab:bounds-rel}
\end{table}
\end{footnotesize}

\paragraph{A posterori bounds.}
A posterori error bounds depend on the input of a program. To illustrate the
potential utility of a posterori absolute error bounds against the more standard
a priori error bounds given by Gappa and FPTaylor, we uniformly sample from the
input range of each benchmark and scatter-plot the corresponding bound. For the
benchmarks in Figure~\ref{fig:mixed-story} , we can see a mixed story: there are
program inputs under which PairFuzz will sometimes provide tighter absolute
error error bounds. For the other 11 benchmarks, the advantages of an a
posteriori error bound is less clear; Gappa and FPTaylor will produce tighter a
priori absolute error bounds.

\begin{figure}[h]
  \centering
  \begin{subfigure}{0.32\columnwidth}
    \centering
    \includegraphics[width=\textwidth]{../plots/rigidBody1.pdf}
    % \caption{First diagram}
    \label{fig:sub1}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.32\columnwidth}
    \centering
    \includegraphics[width=\textwidth]{../plots/rigidBody2.pdf}
    % \caption{Second diagram}
    \label{fig:sub2}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.32\columnwidth}
    \centering
    \includegraphics[width=\textwidth]{../plots/add-assoc.pdf}
    % \caption{Second diagram}
    \label{fig:sub2}
  \end{subfigure}
  \caption{Plots of specific benchmarks where PairFuzz's posterori error bounds
    can sometimes be tighter than Gappa and FPTaylor. Each blue dot represents
    one input-output pair uniformly sampled from the input domain. The large
    dashed red lines represent the a priori absolute error bound given by Gappa
    and the smaller dashed green lines represent the a priori absolute error
    bound given by FPTaylor.}
  \label{fig:mixed-story}
\end{figure}

\paragraph{Performance.}
We now compare the performance of our PairFuzz implementation. Both FPTaylor and
Gappa take different time based on whether absolute or relative error is being
calculuated.
Several of the benchmarks take on the order of milliseconds for PairFuzz and
Gappa to compute. To minimize system noise due to disk reading and caches, we
measure each benchmark by running the benchmark 5 times to warmup the disk
caches and take the median wall-clock time of 50 benchmark runs. All
measurements were taken on a Framework Laptop 13 with a 12th Generation Intel
i7-1280P CPU and 64 GB of RAM on a Debian operating system running in a Xen
hypervisor. As shown in Table~\ref{tab:pref}, we consistently outperform Gappa
and FPTaylor, often by an order of magnitude or more.

\subsection{Evaluation takeaways}
From our evaluation tables and figures, we make three claims:

\paragraph{Our type-based approach is faster than competing approaches.} On our
the benchmarks taken from FPBench that our tool supports, our approach is
signficantly faster than competing approaches, often outperforming by an order
of magnitude. In fact, on the benchmarks we evaluated against, our
implementation was so fast that we found that our parsing and disk reading times
often dominated the total execution time.

\paragraph{Our type-based approach yields useful a priori bounds that are
competitive with other competing approaches.} Our work is the first type-based
approach that is able to reason about forwards round-off error in the presence
of subtraction and negative numbers. Both the absolute error bounds that we
achieve are often comparable to state-of-the-art tools such as Gappa and
FPTaylor. Futher, when tools are able to bound away from zero and provide a
relative error bound, our approach occasionally able to do the same.

\paragraph{A posteriori error bounds can be useful in obtaining tighter
round-off error analyses} We observe our approach on concrete program executions
often produces competitive error bounds. In some circumstances, our type-based
approach can produce a posteriori error bounds that are tighter than Gappa and
FPTaylor. We also observe that our a posteriori error bounds are cheap and
practical to compute given a concrete program output.

