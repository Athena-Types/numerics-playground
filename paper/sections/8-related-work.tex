\section{Related Work}
A major challenge in the automated numerical analysis literature is scalability.
Many existing approaches rely on global optimization \cite{fptaylor}
\cite{satire}, rewrite saturation \cite{gappa}, or SMT-based methods
\cite{rosa}. However, as programs scale, these analysis approaches frequently
time-out. Recent work has applied typed-based analysis approaches to error
analysis, such as Numerical Fuzz \cite{numfuzz} and Bean \cite{bean}. There is
no need to perform global optimization, run an algorithm to convergence,
saturate rewrites, or bit-blast.

