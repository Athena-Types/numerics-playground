\section{Introduction}
It is natural for users such as mathematicians and scientists to desire
programs that operate over the reals. 
As language designers, we wish to show that the floating-point semantics we have
provided is ``close enough".
Towards this end, we develop automated numerical analyses to bound the error
introduced by our floating-point approximations. We wish for our analyses to be
efficient, as automatic as possible, and precise.

A major challenge in the automated numerical analysis literature is scalability.
Many existing approaches rely on global optimization \cite{fptaylor}
\cite{satire}, rewrite saturation \cite{gappa}, or SMT-based methods
\cite{rosa}. However, as programs scale, these analysis approaches frequently
time-out. Type-based techniques offer an alternative approach to automated
numerical analysis that is inherently compositional and scalable: all of the
information necessary to perform an error analysis on a function is contained
within the type. 
% With type checking, there is no need to perform global optimization, run an
% algorithm to convergence, saturate rewrites, or bit-blast.

In this paper, we extend Numerical Fuzz \cite{numfuzz}, an affine call-by-value
graded type system for bounding round-off error.
The core idea of Numerical Fuzz is to track two key properties of each function:
how a function magnifies error in its inputs (function sensitivity), and the
maximum error introduced by the function. This allows Numerical Fuzz to
compositionally bound the maximum accumulated error in a program via a graded
monad.
There are two limitations of Numerical Fuzz that our work addresses:
\begin{enumerate}
  \item \textbf{Lack of support for negative numbers or subtraction:} Subtraction over the
   reals is infinitely-sensitive, which leads Numerical Fuzz to conservatively
   conclude that any use of subtraction might lead to infinite round-off error.
   Since many programs use subtraction or have negative numbers, this limitation
   severely restricts the practical utility of Numerical Fuzz in modeling
   real-world programs.
 \item \textbf{Conservative treatment of addition and subtraction:}
   Floating-point error of addition and subtraction is known to grow in the
   \textit{height} of a computation tree. In Numerical Fuzz, the bounded error
   of a sequence of additions grows in the \textit{number of nodes} in the
   corresponding computation tree. For perfect binary computation trees, this
   leads to a log-factor difference in the obtained error bound. As many
   programs use addition or subtraction, this limits the precision of the
   Numerical Fuzz analysis.
\end{enumerate}

\subsection*{Our approach: Negative Fuzz} 
Supporting subtraction and improving the precision of addition are orthogonal
contributions, so we describe them separately:
% TODO: signpost this approach:
% - sensitivity concern
%   - but wait, we broke it! (how to translate bounds?)
% - dealing with conservative treatment of addition and subtraction

\subsubsection*{Supporting subtraction and negative numbers.} 
To support subtraction and negative numbers, we first introduce a \textit{paired
representation} that simulates the floating-point error of the standard,
unpaired program representation.
Our paired representation associates each possibly negative real $r$ in our
semantics with a pair of non-negative $(a, b)$ such that $r = a - b$.
% Then, we can translate the error over
% $a, b$ to be error over $r$.
Addition and subtraction over the reals can be modeled as an always-growing and
finitely-sensitive addition over the paired components.
To reason about the unpaired and paired representations side-by-side, we use a
triple $(r, a, b)$ where $r \in \mathbb{R}$ and $a, b \in \mathbb{R}^{+}$ and $r
= a - b$. For our paired approach to be useful in bounding the round-off
error on the unpaired $r$ representing real-world floating-point programs, we
need to be able to (1) ``simulate" floating-point round-off error on $r$ a
special error-preserving paired rounding function, (2) measure error on the
paired representation, and (3) use our interval-style bounds analysis to
``translate" error bounds on the paired representation to be back on the
unpaired $r$ representing the real-world program. We defer detailed discussion
of 1-3 to the technical sections of this paper.
% TODO: is the prev line a cop-out?

Our bounds analysis occurs purely in the type system. To aid usability, we
support analyzing functions via \textit{bound polymorphism}, which allows
functions to be polymorphic in the bounds assigned to the inputs and to be
type-checked independently. 
% TODO: hammer the previous point a few more times throughout the paper
To reduce the user type annotation burden, we also
provide a type inference algorithm that can
automatically generalize and instantiate bound-polymorphic functions. We prove
the soundness of our type inference algorithm and evaluate its utility and
performance in Section~\ref{sec:inference}.

% We additionally show that our approach provides no looser error bounds than
% prior type-based approaches while covering many more programs, including those
% with subtraction and negative numbers. We defer the details of our paired
% approach to Section~\ref{sec:encoding} and type inference to
% Section~\ref{sec:inference}. 

\subsubsection*{More precise analysis of addition and subtraction.}
% TODO: fill in factor stuff, intuition and forwards ref
Floating-point addition and subtraction are not associative. In fact, different
associations of the same computation can result in drastically different error
terms. Unfortunately, Numerical Fuzz is not capable of distinguishing between
different associations. We address this limitation by introducing a primitive
which acts like an annotation. We prove that the primitive is type-sound and
show how to use the primitive in Section~\ref{sec:structure}.
% TODO: provide op sem interpretation (reassoc'ing error terms)?

\subsubsection*{Contributions summary.}
Concretely, our contributions are as follows:
\begin{itemize}
  \item We extend the Numerical Fuzz family of languages by incorporating an
    bounds analysis into the type system using \textit{bound polymorphism}. To
    make programs easier and more concise to write, we further extend Numerical
    Fuzz to enable expressions in more places. We prove the soundness of our
    extensions to Numerical Fuzz in (Section~\ref{sec:lang}).

  \item We instantiate Numerical Fuzz to use a \textit{paired representation}
    that allows for modeling subtraction and negative numbers in a
    finitely-sensitive manner (Section~\ref{sec:instantiation}). 
    We provide a polymorphic bounds analysis in the type system to reason about
    our paired representation.
    We provide error soundness theorems to allow the error grade and bounds
    analysis from program type to be translated into a floating-point error
    bound on the standard, unpaired program representation.
    % TODO: how do we show that this is non-trivial without talking too much
    % about type inference and bound polymorphism. does this do the job? feels a
    % bit understated here

    % TODO: some claim about novelty is needed to put this contribution in context
    % to develop the first type-based approach to forwards error analysis that
    % enables
    % Our instantiation relies on a \textit{paired numeric representation}. 
    % To our knowledge, our approach is the first automatic general-purpose
    % numerical analysis that can produce usable \textit{a posteori} error bounds.
    
    % We prove that error types can be used to provide both \textit{a priori} and
    % \textit{a posterori} compositional error bounds in the presence of
    % subtraction and negative numbers (Section~\ref{sec:application}). 

  \item We improve the precision of Numerical Fuzz by allowing the analysis to
    more efficiently reason about addition and subtraction. This lets us achieve
    a log-factor improvement on the error bounds of a program representing
    pairwise summation. We accomplish this by introducing a
    previously-untypable primitive that can more accurately capture different
    techniques for sequencing addition and subtraction operations
    (Section~\ref{sec:structure}).

  % \item We enable the precise structuring and seqeuncing of arithmetic by
  %   allowing error and sensitivities in rounded terms to be shared. We
  %   accomplish this through the addition of a previously-untypable primitive
  %   inspired by the resource interpretation of linear logic
  %   (Section~\ref{sec:structure}). 

  \item We develop a type inference algorithm for our type system that can
    automatically infer function sensitivities, round-off error bounds, and
    bound polymorphism in many useful programs; the user merely supplies a
    program without bound polymorphism, sensitivity annotations, or round-off
    grades. We prove the soundness of our type inference algorithm.
    We further show that our approach leads to forwards error bounds no looser
    than Numerical Fuzz for programs that can be typed by Numerical Fuzz
    (Section~\ref{sec:tightness}). 

  \item We implement our type-based approach for error analysis. 
    Our approach is faster than competing approaches, mostly automatic with low
    type annotation overhead, and competitive on precision with other
    state-of-the-art techniques.
    When compared against competing approaches (FPTaylor, Gappa and Satire) on a
    suite of benchmarks translated into our core language, we obtain useful and
    competitive error bounds with faster and more scalable performance
    (Section~\ref{sec:eval}).
    % TODO: put in hard numbers
\end{itemize}


