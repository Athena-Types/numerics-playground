\section{Language} \label{sec:lang}
We are interested in developing a modular family of languages for analyzing
numerical round-off error. Modularity enables differing floating-point bit
precisions (e.g. 32-bit floats, 64-bit floats) and floating-point operations to
be soundly instantiated.

% In this section, we detail the construction of our modular family of languages.
% We extend the Numerical Fuzz family of languages to support two key features:
% \begin{enumerate}
%   \item Error and sensitivity sharing between terms, through the addition of a
%   \textbf{factor} primitive (Section~\ref{sec:error-sharing}). This enables more
%   programs to be typed with tighter error bounds.
%   % todo: add section ref
%   \item Interval analysis, through the incorporation of \textit{bound
%   polymorphism} (Section~\ref{sec:bound-poly}). In
%   (Section~\ref{sec:tightness}), we will prove that this will result in error
%   bounds no looser than prior type-based approaches for forwards analysis.
% \end{enumerate}
% Finally, we
% provide a formal specification for soundly instantiating a particular
% language and prove soundness via a logical relations argument.
%
% \subsection{Sharing Error} \label{sec:error-sharing}
%
% \subsection{Type-based Interval Analysis and Bound Polymorphism} \label{sec:bound-poly}

\subsection{Syntax}
We present the full syntax for types, terms, and evaluation contexts in
Figure~\ref{fig:syntax}. Our language is an extension of the Numerical Fuzz
\cite{NumFuzz} language, a call-by-value affine lambda calculus.

\subsubsection*{Types}
Our type system has monad types $M_u \tau$ for tracking the round-off error in
$\tau$ and bounding it by a real, non-negative grade $u$, scaled metric types
$!_s \tau$, and linear function types $\tau_0 \multimap \tau$ for 1-sensitive
functions. We also also incorporate an interval-style analysis by annotating
$\textbf{num}_{\bnd{i}}$ types with a subscript bound with the grammar $\bnd{i}$
shown in Figure~\ref{fig:syntax}. For the remainder of this paper we use the
color $\bnd{\textit{blue}}$ to denote bound polymorphism.

Many programs we wish to type call the same function many times. To ensure that
our interval analysis is scalable and that functions types can be reused, we
support \textit{bound polymorphism}, which allows us to specialize our function
to have different concrete bounds for each function call site. We write types
$\tau$ polymorphic in interval variable $\epsilon$ as $\forall \epsilon. \tau$.

\subsubsection*{Terms}
Our term syntax has explicit terms to represent polymorphic abstraction
$\bnd{(\Lambda \epsilon. e)}$ and instantiation $\bnd{(e \{i\})}$. We also have
explicit terms to represent scaling ($[e]$), rounding ($\textbf{rnd}~e$).
For sequencing and combining computation, we have $\textbf{let}$,
$\textbf{let-pair}$, $\textbf{let-bind}$, and $\textbf{let-cobind}$ for
sequencing assignment, tuple unpacking, monadic, and comonadic computations
respectively.

In linear and affine logic, we have the alternative conjunction $\tau_0 \times
\tau_1$, (sometimes written $\tau_0~\&~\tau_1$). We can view the introduction
rule as allowing $\tau_0$ and $\tau_1$ to share resources in $\Gamma$, their
construction. Correspondingly, the elimination rules can be viewed as forcing
consumers to internally choose between allocating the resources in $\Gamma$
towards either constructing $\tau_1$ or $\tau_2$.

However, the ability to share resources interacts poorly with our sequenced
$\textbf{let-bind}$ and call-by-value evaluation strategy, which pessimistically
prohibits the sharing of resources between the bound argument and the body. As a
toy example, if we have two monadic types $M_q \tau_0 \times M_q \tau_1$ that
shared resources in their construction, we have no way of constructing $M_q
(\tau_0 \times \tau_1)$ with a shared error grade. A similar problem exists for
sharing context sensitivities. To enabling the sharing of round-off and
sensitivity information, we introduce a new primitive new primitive
($\textbf{factor} : (M_q \tau_0 \times M_r \tau_1) \multimap M_{max(q, r)}
(\tau_0 \times \tau_1)$) which allows for error and sensitivity information to
be shared between monadic terms.


\subsubsection*{Evaluation contexts}
We extend the Numerical Fuzz language to allow expressions in more places. To
separate the structural plumbing of the operational semantics from the more
interesting portions of the operational semantics, we define evaluation
contexts.

\input{sections/01-syntax.tex}

\subsection{Static Semantics}
Our static semantics extends Numerical Fuzz by adding expressions in more places
(e.g. the application rule), a $\textbf{factor}$ primitive, and bound
polymorphism. We outline the two key additions below.

\subsubsection*{Factoring and Distributing Error}
Suppose, by way of example, that we wish to compute the sum 
$w~\tilde{+}~x~\tilde{+}~y~\tilde{+}~z$, where $\tilde{+}$ represents addition
with round-off error.
It is well known that round-off error grows linearly in the height of a
summation tree. So, a user might naturally want to sequence the summation as
a perfect binary tree: $(w~\tilde{+}~x)~\tilde{+}~(y~\tilde{+}~z)$.
However Numerical Fuzz forces all monadic computation to be sequenced, forcing
the error analysis 
to always compute the worst-case round-off error associated with the
pathological degenerate tree: $((w~\tilde{+}~x)~\tilde{+}~y)~\tilde{+}~z$.

Our extension enables the user to structure the computation tree arbitrarily,
providing tighter error bounds when possible. It is inspired by the resource
interpretation of linear logic: we can either give our error budget $M_q$ to
$\tau_0$ or $\tau_1$ or equivalently give the same error budget $M_q$ to
$\tau_0$ \textit{with} $\tau_1$. To show that $M_q ~ (\tau_0 \times \tau_1)$
is equivalent to
$(M_q ~ \tau_0) \times (M_q \tau_1)$, we need to construct two 1-sensitive
functions in the forwards and backwards direction.

The program $\textbf{distribute} : M_q (\tau_0 \times \tau_1) \multimap (M_q \tau_0)
\times (M_q \tau_1)$ is derivable in Numerical Fuzz, so no special primitive is
needed:
\begin{equation*} \label{eq:distribute}
\begin{aligned}[c]
\textbf{distribute} &: M_q (\tau_1 \times \tau_2) \multimap (M_q \tau_1 \times M_q \tau_2) \\
 & \triangleq \lambda ~ y. ~ 
   \langle
     \textbf{let-bind} \ x ~ = ~ y \ \textbf{in} \ \textbf{ret}(\pi_1 ~ x),
     \textbf{let-bind} \ x ~ = ~ y \ \textbf{in} \ \textbf{ret}(\pi_2 ~ x),
   \rangle
\end{aligned}
\end{equation*}

By contrast, inverse program $\textbf{factor}: (M_q \tau_0) \times (M_q \tau_1)
\multimap M_q (\tau_0 \times \tau_1)$ is neither derivable nor admissible (but
is sound). $\textbf{factor}$ is a particularly useful primitive to have for
sequencing computations. For example, consider the following side-by-side
comparison in Figure~\ref{fig:factor-side-by-side} with interval bounds erased
for presentational purposes.

\begin{figure}[ht]
\centering

\begin{subfigure}[t]{0.48\textwidth}
\begin{lstlisting}
// (w + x) + (y + z) : M[3*u] num 
let-bind a = addfp <w, x> in
let-bind b = addfp <y, z> in
let-bind c = addfp <a, b> in
addfp c 
\end{lstlisting}
\caption{Without factor}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.48\textwidth}
\begin{lstlisting}
// (w + x) + (y + z) : M[2*u] num 
let-bind a = 
  factor <addfp <w, x>, addfp <y, z>> in
  addfp a
\end{lstlisting}
\caption{With factor}
\end{subfigure}

\caption{Side-by-side comparison with and without the \textbf{factor} primitive.}
\label{fig:factor-side-by-side}
\end{figure}
Note that $u$ represents the unit round-off associated with $addfp :
\textbf{num} \times \textbf{num} \multimap M_u \textbf{num}$. In the summation
example, the program with factor has an error bound of two ULPs whereas the
program without factor has an error bound of three ULPs. Clearly,
$\textbf{factor}$ helps users design programs that achieve tighter error bounds.

\subsubsection*{Interval analysis and bound polymorphism}
We wish to extend the type system to be able to perform an interval analysis. A
naive approach would be to annotate each $\textbf{num}_{\bnd{i}}$ with a
subscript interval $\bnd{i}$. However, if we have a function, such as the
identity function over numbers $id : \textbf{num}_{\bnd{i}} \multimap
\textbf{num}_{\bnd{i}}$ called at two different call sites with intervals $j$
and $k$, the inferred bound for $i$ would be $j \cup k$.

To solve this problem, we add bounds and \textit{bound polymorphism} for
functions, allowing the functions to be typed like so: $id : \bnd{\forall
\epsilon.} ~ \textbf{num}_{\bnd{\epsilon}} \multimap
\textbf{num}_{\bnd{\epsilon}}$. We can introduce and eliminate polymorphism via
the $\forall$ introduction and elimination rules provided in
Figure~\ref{fig:typing_rules}.

\input{sections/02-static-semantics.tex}

\subsection{Dynamic Semantics}
We only define our language over closed terms. In Figure~\ref{fig:typing_rules},
we define the operational semantics rewrite relation $\mapsto$ to map from
closed terms in \Lang to closed terms in \Lang.

We use evaluation contexts and the characteristic \textit{context rule} to
simplify reasoning about the rewrite relation. Our rewrite relation has a
restricted ability to step interval bounds and eliminate polymorphic variables.
For example, the bound $(0, 1) + (2,3) \mapsto (2, 4)$.

\input{sections/03-dynamic-semantics.tex}

\subsection{Logical Relation}
\input{sections/04-denotational-semantics.tex}

\subsection{Modular Interface}
The following notation is to mirror the look of the Fuzz metric preservation
theorem statement but contains differences in the setup. For example, our
logical relation is neither coinductive nor step-indexed. It is also unary,
using mutual (well-founded) recursion between the definition of a syntactic term
falling within the logical relation and the definition of the syntactic distance
between terms.

For any two closed bounds, we can write $i \sim_0 i$ or $i \sim_{\infty} i$. 
For any two closed expressions $e_0, e_1$ falling in same type relation $e_0,
e_1 \in R_\tau$ (where $\tau$ is a closed type), we can write $e_0 \sim_r e_1$
where $\mathcal{SD}_{\tau}(e_0, e_1) \leq r$. 
Generally, we can write vectors of expressions (e.g. for subsitutions) $\sigma =
\sigma_{\Delta} \ | \ \sigma_{\Gamma}, \sigma' = \sigma'_{\Delta} \ | \
\sigma'_{\Gamma}$
for a given typing context $\Delta \ | \ \Gamma$ such that: $\sigma \sim_{\gamma} \sigma'
: \Delta \ | \ \Gamma$ for a \textit{distance vector}
$\gamma = r_0, r_1, \ldots$
where
$\sigma = (k^l_0, k^r_0),~(k^l_1, k^r_1),~\ldots \ | \ e_0,~e_1,~\ldots$ 
and 
$\sigma' = (k'^l_0, k'^r_0),~(k'^l_1, k'^r_1),~\ldots \ | \ e_0,~e_1,~\ldots$ 
such that:
$$
(k^l_0, k^r_0) \sim_{r_0} (k'^l_0, k'^r_0) : \mathbf{bnd},~(k^l_1, k^r_1) \sim_{r_1} (k'^l_1, k'^r_1) : \mathbf{bnd},~\ldots \
| \ e_0 \sim_{r_m} e'_0 :
\tau_0~[\sigma_{\Delta}],~e_0 \sim_{r_{m+1}} e'_0 :
\tau_1~[\sigma_{\Delta}],~\ldots
$$
We also say that a substitution vector 
$[(k^l_0, k^r_0) / \epsilon_0, (k^l_1, k^r_1) / \epsilon_1, \ldots \ | \ e_1/x_1, e_2/x_2, \ldots]$ 
is \textit{compatible} with a typing context 
$i_0 : \mathbf{bnd}, i_1 : \mathbf{bnd}, \ldots \ | \ x_1 : \tau_1, x_2 : \tau_2, \ldots$
if each term 
$(k^l_0, k^r_0) \in \mathcal{R}_{\mathbf{bnd}}, 
(k^l_1, k^r_1) \in \mathcal{R}_{\mathbf{bnd}}, 
\ldots \ | 
\ e_1 \in \mathcal{R}_{\tau_1~[\sigma_{\Delta}]}, 
e_2 \in \mathcal{R}_{\tau_2~[\sigma_{\Delta}]}, \ldots$ where all types are closed.

Our definition for the dot product of a distance vector is the same as Fuzz. We
also write, for a distance vector $\gamma$ and variable $x$, $\gamma(x)$ for the
lookup of the distance of variable $x$ in $\gamma$. If the variable $x$ is not
in the domain, $\gamma(x) = 0$ by default. From here on in the paper, we'll
treat and represent our distance vector $\gamma$ as a lookup function and assume
that there is an implicit fixed ordering on the variables.

Numerical Fuzz is a modular family of programming langauges paramterized by the
appropriate $\rho$, constant parameter $u$, and the appropriate set of numeric
computations $\Sigma$.  
We can now state a few assumptions about how the operational and static
semantics of $\mathbf{rnd}$ and $\Sigma$ (for $\mathbf{op}$) relate.
It is the proof obligation for any language designer instantiating the language
to demonstrate that these properties hold in order for our paramterized
soundness theorems to follow.
\begin{definition}[Interface for instantiating Numerical Fuzz.]
  \label{def:numfuzz-interface}
  The interface for Numerical Fuzz consists of $\rho$, $u$, $\Sigma$, and
  $\Sigma_{\mathbf{bnd}}$ such that the following properties hold: 
\begin{description}
  \item[a) Property of $\rho$ and constant parameter $u$.] We assume that the
    $\forall e \in \mathcal{R}_{num}, \mathcal{SD}_{\mathbf{num}}(\rho(e), e)
    \leq q$ where $q$ is the grade in the $\mathbf{rnd}$ typing rule.
  \item[b) Property of $\mathbf{op}$.] 
    We can view $\textit{op}$ as a (possibly constant) metalevel function.
    We also assume that for every operation
    $\mathbf{op} : \tau \in \ \Sigma$ we have a
    corresponding function $op$ mapping syntactic values in
    $\mathcal{VR}_{\tau}$ where metric preservation holds: For all $\sigma
    \sim_{\gamma} \sigma' : \Gamma$, $\textit{op}~\sigma \sim_{\gamma \cdot
    \Gamma} \textit{op} : \tau$.
    Or, expanded:
    \begin{description}
      \item[\underline{1) Type denotation.}] $\mathit{op} \in
        \mathcal{R}_{\tau}$. The metalevel operation will step to something in the
        value relation.
      \item[\underline{2) Context sensitivity.}]
        This property states that for every $\textbf{op}$, the
        corresponding $\textit{op}$ preserves the metric. For any two
        substitutions $\sigma, \sigma'$ such that:
        $\sigma \sim_{\gamma} \sigma' : \Gamma$
        we have that
        $\mathcal{SD}_{\tau}(\textit{op}~\sigma, \textit{op}~\sigma') \leq \gamma \cdot \Gamma$.
    \end{description} \item[c) Property of $\mathbf{iop}$.] We further need to
      assume that for every operation $\mathbf{iop}_c : \Sigma_\textbf{num}$, we
      have that for any sequence of bounds $b_0, b_1, \ldots : \textbf{bnd}$ the
      corresponding metalevel function will actually map to a concrete bound
      where $\textit{iop}_c(b_0, b_1, \ldots) : \textbf{bnd} = (k_0, k_1)$
      holds.
\end{description}
\end{definition}

\subsection{Soundness}
\input{sections/05-type-error-soundness.tex}

