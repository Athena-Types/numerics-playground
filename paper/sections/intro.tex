\section{Introduction}
It is natural for ordinary programmers such as mathematicians and scientists to
wish their computers operate over the reals. 
But this is impossible and programming languages typically compute over the
finitary floating-point number approximation.
As language designers, we wish to convince the ordinary programmer, who are
largely not experts in numerical analysis, that the floating-point semantics we
have provided is ``close enough" to what they desire.
Towards this end, we develop automated numerical analyses to bound the error
introduced by our floating-point approximations.

A major challenge in the automated numerical analysis literature is scalability.
Many existing approaches rely on global optimization \cite{fptaylor}
\cite{satire}, rewrite saturation \cite{gappa}, or SMT-based methods
\cite{rosa}. However, as programs scale, these analysis approaches frequently
time-out. Recent work has applied typed-based analysis approaches to both
forwards and backwards error analysis, such as Numerical Fuzz \cite{numfuzz} and
Bean \cite{bean}. The advantage of type-based methods is that they are
inherently compositional and scalable: all of the information necessary to
perform an error analysis on a function is contained within the function type.
There is no need to perform global optimization, run an algorithm to
convergence, saturate rewrites, or bit-blast.

However, prior type-based work for forwards error analysis is not capable of
handling negative numbers and subtraction. The problem is essentially:
compositional type-based error bounds seem to require relative notions of error;
however, relative notions of error are not well-behaved in the presence of
subtraction and negative numbers. This phenomenon is known as
\textit{catastrophic cancellation}: two large nearby numbers with small relative
error can be subtracted to produce a small number with arbitrarily high relative
error.

In this paper, we are interested in addressing the above limitations by
providing a type-based forwards error analysis that can handle broader classes
of programs and, at the same time, tighten error bounds. 
Concretely, our contributions are as follows:
\begin{itemize}
  \item We develop the first type-based approach to forwards error analysis that
    enables both \textit{a priori} and \textit{a posterori} compositional error
    bounds in the presence of subtraction and negative numbers. We prove that
    our approach, which can handle strictly more programs, leads to forwards
    error bounds no looser than prior type-based work for forwards analysis.

  \item We extend Numerical Fuzz by introducing a previously-untypable primitive
    that enables the error and sensitivities in rounded terms to be shared,
    allowing for tighter error bounds. We also extend Numerical Fuzz to enable
    expressions in more places. We prove the soundness of these extensions to
    Numerical Fuzz.

  \item We implement our type-based approach for forwards error analysis. We
    evaluate our implementation against FPTaylor and Gappa on a suite of
    benchmarks translated into our core language and demonstrate that we obtain
    competitive error bounds with often faster performance.
    % todo: put in hard numbers
\end{itemize}
